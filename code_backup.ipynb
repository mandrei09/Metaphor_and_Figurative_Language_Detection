{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8374710,"sourceType":"datasetVersion","datasetId":4979263}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -U transformers accelerate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-10T11:10:27.014712Z","iopub.execute_input":"2024-05-10T11:10:27.015238Z","iopub.status.idle":"2024-05-10T11:10:58.950545Z","shell.execute_reply.started":"2024-05-10T11:10:27.015207Z","shell.execute_reply":"2024-05-10T11:10:58.948119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import BertTokenizer, BertForMultipleChoice, Trainer, TrainingArguments\nfrom datasets import Dataset, DatasetDict\n\n# Load the dataset from CSV files\ndef load_figqa_dataset(train_path, dev_path, test_path):\n    train_df = pd.read_csv(train_path)\n    dev_df = pd.read_csv(dev_path)\n    test_df = pd.read_csv(test_path)\n\n    # Ensure label columns are correctly named\n    train_df.rename(columns={'labels': 'label'}, inplace=True)\n    dev_df.rename(columns={'labels': 'label'}, inplace=True)\n    test_df.rename(columns={'labels': 'label'}, inplace=True)\n\n    # Assign a default value to 'label' in the test dataset if it doesn't exist\n    if 'label' not in test_df.columns:\n        test_df['label'] = -1\n\n    # Convert DataFrames to Dataset objects\n    train_dataset = Dataset.from_pandas(train_df)\n    dev_dataset = Dataset.from_pandas(dev_df)\n    test_dataset = Dataset.from_pandas(test_df)\n\n    return DatasetDict({\n        'train': train_dataset,\n        'dev': dev_dataset,\n        'test': test_dataset\n    })\n\n# Preprocess function for multiple-choice questions\ndef preprocess_function(examples):\n    first_sentences = [[context] * 2 for context in examples['startphrase']]\n    question_headers = [examples['ending1'], examples['ending2']]\n    choices = list(map(list, zip(*question_headers)))\n\n    first_sentences = sum(first_sentences, [])\n    choices = sum(choices, [])\n\n    tokenized_examples = tokenizer(\n        first_sentences,\n        choices,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128\n    )\n\n    return {\n        'input_ids': [tokenized_examples['input_ids'][i:i + 2] for i in range(0, len(tokenized_examples['input_ids']), 2)],\n        'attention_mask': [tokenized_examples['attention_mask'][i:i + 2] for i in range(0, len(tokenized_examples['attention_mask']), 2)],\n        'labels': examples['label']\n    }\n\n# Define paths for dataset\ntrain_path = '/kaggle/input/nlpproject/train_xl.csv'\ndev_path = '/kaggle/input/nlpproject/dev.csv'\ntest_path = '/kaggle/input/nlpproject/train_s.csv'\n\n# Load the Fig-QA dataset\ndataset = load_figqa_dataset(train_path, dev_path, test_path)\n\n# Initialize the tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForMultipleChoice.from_pretrained('bert-base-uncased')\n\n# Apply the preprocessing function to the dataset\nencoded_dataset = dataset.map(preprocess_function, batched=True)\n\n# Check and remove unnecessary columns\ncolumns_to_remove = ['startphrase', 'ending1', 'ending2', 'valid']\nfor col in columns_to_remove:\n    if col in encoded_dataset['test'].column_names:\n        encoded_dataset = encoded_dataset.remove_columns([col])\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model='accuracy',\n    save_strategy='epoch',\n    save_total_limit=2,\n    report_to=[]  # Disable W&B\n)\n\n# Define a function to compute evaluation metrics\ndef compute_metrics(p):\n    predictions, labels = p\n    preds = predictions.argmax(axis=1)\n    return {'accuracy': (preds == labels).mean()}\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset['train'],\n    eval_dataset=encoded_dataset['dev'],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# Start training\ntrainer.train()\n\n# Evaluate the model on the evaluation set\neval_results = trainer.evaluate()\nprint(f\"Evaluation Results: {eval_results}\")\n\n# Make predictions on the test dataset\ntest_predictions = trainer.predict(encoded_dataset['test'])\n\n# Extract the predicted labels\npredictions = test_predictions.predictions.argmax(axis=1)\n\n# Load original test data for context\ntest_df = pd.read_csv(test_path)\n\n# Add predicted labels to the DataFrame\ntest_df['predicted'] = predictions\n\n# Save to a new CSV file\noutput_csv_path = './results/test_predictions.csv'\ntest_df.to_csv(output_csv_path, index=False)\nprint(f\"Predictions saved to {output_csv_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:47:59.486780Z","iopub.execute_input":"2024-05-14T19:47:59.487101Z","iopub.status.idle":"2024-05-14T20:00:20.864050Z","shell.execute_reply.started":"2024-05-14T19:47:59.487074Z","shell.execute_reply":"2024-05-14T20:00:20.863147Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-14 19:48:11.373557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 19:48:11.373668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 19:48:11.555438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e592ee5b5042249b39d738a69f23c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db0744840485472881dabc9905053303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e35ce417140f429ca07a97826d643d63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c5c88cc41741ef89e65df761ed17cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c11cd8903ca4fa89ca3eac7f92f322c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8016 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e1d4cf229ad4538a23dfafb4d494e6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1094 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20487df26254c4d8beb4561b2340d47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e3969021dd6403d880dfad173adf678"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1503' max='1503' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1503/1503 11:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.492000</td>\n      <td>0.440337</td>\n      <td>0.790676</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.448000</td>\n      <td>0.371158</td>\n      <td>0.836380</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.263000</td>\n      <td>0.402555</td>\n      <td>0.840951</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.4025554060935974, 'eval_accuracy': 0.8409506398537477, 'eval_runtime': 10.8392, 'eval_samples_per_second': 100.93, 'eval_steps_per_second': 6.366, 'epoch': 3.0}\nPredictions saved to ./results/test_predictions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}